# -*- coding: utf-8 -*-
###############################################################################
# Copyright (c), The AiiDA-CP2K authors.                                      #
# SPDX-License-Identifier: MIT                                                #
# AiiDA-CP2K is hosted on GitHub at https://github.com/aiidateam/aiida-cp2k   #
# For further information on the license, see the LICENSE.txt file.           #
###############################################################################
"""AiiDA-CP2K input plugin"""

from __future__ import absolute_import
from __future__ import division

from itertools import chain
from copy import deepcopy
import math

import six
import regex as re


class Cp2kInput:
    """Transforms dictionary into CP2K input"""

    DISCLAIMER = "!!! Generated by AiiDA !!!"

    def __init__(self, params=None):
        if not params:
            self._params = {}
        else:
            # always make a full copy to avoid that add_keyword() changes the
            # passed-in dictionary
            self._params = deepcopy(params)

    def add_keyword(self, kwpath, value):
        """
        Add a value for the given keyword.

        Args:
            kwpath: Can be a single keyword, a path with `/` as divider for sections & key,
                    or a sequence with sections and key
            value: the value to set the given key to
        """

        if isinstance(kwpath, six.string_types):
            kwpath = kwpath.split("/")

        Cp2kInput._add_keyword(kwpath, value, self._params)

    def to_string(self):
        output = [self.DISCLAIMER]
        self._render_section(output, self._params)
        return "\n".join(
            chain([self.DISCLAIMER], Cp2kInput._render_section(self._params))
        )

    def to_file(self, fhandle):
        fhandle.write(u"{self.DISCLAIMER}".format(self=self))
        for line in Cp2kInput._render_section(self._params):
            fhandle.write(u"\n{line}".format(line=line))

    @staticmethod
    def _add_keyword(kwpath, value, params):
        """Add keyword in given nested dictionary"""

        if len(kwpath) == 1:  # key/value for the current level
            params[kwpath[0]] = value
            return

        if kwpath[0] not in params.keys():  # create an empty section if necessary
            params[kwpath[0]] = {}

        Cp2kInput._add_keyword(kwpath[1:], value, params[kwpath[0]])

    @staticmethod
    def _render_section(params, indent=0, indent_width=3):
        """
        It takes a dictionary and recurses through.

        For key-value pair it checks whether the value is a dictionary
        and prepends the key with & (CP2K section)
        It passes the valued to the same function, increasing the indentation
        If the value is a list, I assume that this is something the user
        wants to store repetitively
        eg:
            dict['KEY'] = ['val1', 'val2']
            ===>
            KEY val1
            KEY val2

            or

            dict['KIND'] = [{'_': 'Ba', 'ELEMENT':'Ba'},
                            {'_': 'Ti', 'ELEMENT':'Ti'},
                            {'_': 'O', 'ELEMENT':'O'}]
            ====>
                  &KIND Ba
                     ELEMENT  Ba
                  &END KIND
                  &KIND Ti
                     ELEMENT  Ti
                  &END KIND
                  &KIND O
                     ELEMENT  O
                  &END KIND
        """

        if six.PY2:
            from collections import Mapping, Sequence
        else:
            from collections.abc import Mapping, Sequence

        for key, val in sorted(params.items()):
            # the `_` is reserved for section params and evaluated in the prior call
            if key == "_":
                continue

            # keys are not case-insensitive, ensure that they follow the current scheme
            if key.upper() != key:
                raise ValueError("keyword '{key}' not upper case".format(key=key))

            if key.startswith(("@", "$")):
                raise ValueError("CP2K preprocessor directives not supported")

            ispace = " " * indent

            if isinstance(val, Mapping):
                line = "{ispace}&{key}".format(ispace=ispace, key=key)
                if "_" in val:  # if there is a section parameter, add it
                    line += " {}".format(val["_"])

                yield line
                # once we are on Python3-only, replace the following with a `yield from ...`
                for item in Cp2kInput._render_section(val, indent + indent_width):
                    yield item
                yield "{ispace}&END {key}".format(ispace=ispace, key=key)

            elif isinstance(val, Sequence) and not isinstance(val, six.string_types):
                for listitem in val:
                    # once we are on Python3-only, replace the following with a `yield from ...`
                    for line in Cp2kInput._render_section({key: listitem}, indent):
                        yield line

            elif isinstance(val, bool):
                val_str = ".TRUE." if val else ".FALSE."
                yield "{ispace}{key} {val_str}".format(
                    ispace=ispace, key=key, val_str=val_str
                )

            else:
                yield "{ispace}{key} {val}".format(ispace=ispace, key=key, val=val)


FP_EXPR = r"[\+\-]?(\d*[\.]\d+|\d+[\.]?\d*)([Ee][\+\-]?\d+)?"

CP2K_CONDITION_NUMBER_MATCH = re.compile(
    r"""
# anchor to indicate beginning the overlap matrix condition number section
^[ \t]* OVERLAP\ MATRIX\ CONDITION\ NUMBER\ AT\ GAMMA\ POINT [ \t]* \n
 [ \t]* 1-Norm\ Condition\ Number\ \(Estimate\) [ \t]* \n
 [ \t]* CN\ :\ \|A\|\*\|A\^-1\|:
   [ \t]* (?P<norm1_estimate_A>{fp})
   [ \t]* \*
   [ \t]* (?P<norm1_estimate_Ainv>{fp})
   [ \t]* =
   [ \t]* (?P<norm1_estimate>{fp})
   [ \t]* Log\(1-CN\):
   [ \t]* (?P<norm1_estimate_log>{fp})
   [ \t]* \n

 [ \t]* 1-Norm\ and\ 2-Norm\ Condition\ Numbers\ using\ Diagonalization [ \t]* \n

 [ \t]* CN\ :\ \|A\|\*\|A\^-1\|:
   [ \t]* (?P<norm1_diag_A>{fp}) [ \t]* \* [ \t]* (?P<norm1_diag_Ainv>{fp})
   [ \t]* =
   [ \t]* (?P<norm1_diag>{fp}) [ \t]* Log\(1-CN\): [ \t]* (?P<norm1_diag_log>{fp})
   [ \t]* \n

 [ \t]* CN\ :\ max/min\ ev:
   [ \t]* (?P<norm2_diag_max_ev>{fp}) [ \t]* / [ \t]* (?P<norm2_diag_min_ev>{fp})
   [ \t]* =
   [ \t]* (?P<norm2_diag>{fp}) [ \t]* Log\(2-CN\): [ \t]* (?P<norm2_diag_log>{fp})
   [ \t]* \n
""".format(
        fp=FP_EXPR
    ),
    re.MULTILINE | re.VERBOSE,
)


CP2K_MULLIKEN_MATCH = re.compile(
    r"""
(?(DEFINE)(?P<fp>[\+\-]?(\d*[\.]\d+|\d+[\.]?\d*)([Ee][\+\-]?\d+)?))
# anchor to indicate beginning of the Mulliken Population Analysis
^[ \t]* Mulliken\ Population\ Analysis [ \t]* \n
 [ \t]* \n
 [ \t]* \#  [\w \t\,\(\)]+\n  # match the header
(
  ^
  [ \t]*
  (?P<atom>\d+) [ \t]+
  (?P<element>\w+) [ \t]+
  (?P<kind>\d+) [ \t]+
  (
    ( # spin unrestricted case:
      (?P<population_alpha>(?&fp)) [ \t]+ (?P<population_beta>(?&fp)) [ \t]+
      (?P<charge>(?&fp)) [ \t]+ (?P<spin>(?&fp))
    )
    |
    (
      (?P<population>(?&fp)) [ \t]+
      (?P<charge>(?&fp))
    )
  ) [ \t]*
  \n
)+
^ [ \t]* \#\ Total\ charge (\ and\ spin)? [ \t]+
(
  ( # spin unrestricted case:
    (?P<total_population_alpha>(?&fp)) [ \t]+ (?P<total_population_beta>(?&fp)) [ \t]+
    (?P<total_charge>(?&fp)) [ \t]+ (?P<total_spin>(?&fp))
  )
  |
  (
    (?P<total_population>(?&fp)) [ \t]+
    (?P<total_charge>(?&fp))
  )
) [ \t]*
\n
""",
    re.VERSION1 | re.MULTILINE | re.VERBOSE,
)


def parse_cp2k_output(fobj):
    content = fobj.read()
    lines = content.splitlines()

    result_dict = {"exceeded_walltime": False}

    for i_line, line in enumerate(lines):
        if line.startswith(" ENERGY| "):
            result_dict["energy"] = float(line.split()[8])
            result_dict["energy_units"] = "a.u."
        elif "The number of warnings for this run is" in line:
            result_dict["nwarnings"] = int(line.split()[-1])
        elif "exceeded requested execution time" in line:
            result_dict["exceeded_walltime"] = True
        elif "KPOINTS| Band Structure Calculation" in line:
            kpoints, labels, bands = _parse_bands(lines, i_line)
            result_dict["kpoint_data"] = {
                "kpoints": kpoints,
                "labels": labels,
                "bands": bands,
                "bands_unit": "eV",
            }
        else:
            # ignore all other lines
            pass

    match = CP2K_CONDITION_NUMBER_MATCH.search(content)
    if match:
        captures = match.groupdict()

        result_dict["overlap_matrix_condition_number"] = {
            "1-norm (estimate)": {
                "|A|": float(captures["norm1_estimate_A"]),
                "|A^-1|": float(captures["norm1_estimate_Ainv"]),
                "CN": float(captures["norm1_estimate"]),
                "Log(CN)": float(captures["norm1_estimate_log"]),
            },
            "1-norm (using diagonalization)": {
                "|A|": float(captures["norm1_diag_A"]),
                "|A^-1|": float(captures["norm1_diag_Ainv"]),
                "CN": float(captures["norm1_diag"]),
                "Log(CN)": float(captures["norm1_diag_log"]),
            },
            "2-norm (using diagonalization)": {
                "max EV": float(captures["norm2_diag_max_ev"]),
                "min EV": float(captures["norm2_diag_min_ev"]),
                "CN": float(captures["norm2_diag"]),
                "Log(CN)": float(captures["norm2_diag_log"]),
            },
        }

    match = CP2K_MULLIKEN_MATCH.search(content)
    # for this one we needed the extended regex library https://pypi.python.org/pypi/regex
    if match:
        captures = match.capturesdict()
        per_atom = []

        if captures.get("population_alpha"):
            for idx in range(len(captures["atom"])):
                per_atom.append(
                    {
                        "element": captures["element"][idx],
                        "kind": int(captures["kind"][idx]),
                        "population_alpha": float(captures["population_alpha"][idx]),
                        "population_beta": float(captures["population_beta"][idx]),
                        "charge": float(captures["charge"][idx]),
                        "spin": float(captures["spin"][idx]),
                    }
                )

            result_dict["mulliken_population_analysis"] = {
                "per-atom": per_atom,
                "total": {
                    "population_alpha": float(captures["total_population_alpha"][0]),
                    "population_beta": float(captures["total_population_beta"][0]),
                    "charge": float(captures["total_charge"][0]),
                    "spin": float(captures["total_spin"][0]),
                },
            }
        else:
            for idx in range(len(captures["atom"])):
                per_atom.append(
                    {
                        "element": captures["element"][idx],
                        "kind": int(captures["kind"][idx]),
                        "population": float(captures["population"][idx]),
                        "charge": float(captures["charge"][idx]),
                    }
                )

            result_dict["mulliken_population_analysis"] = {
                "per-atom": per_atom,
                "total": {
                    "population": float(captures["total_population"][0]),
                    "charge": float(captures["total_charge"][0]),
                },
            }

    return result_dict


def _parse_bands(lines, n_start):
    """Parse band structure from cp2k output"""

    import numpy as np

    kpoints = []
    labels = []
    bands_s1 = []
    bands_s2 = []
    known_kpoints = {}
    pattern = re.compile(".*?Nr.*?Spin.*?K-Point.*?", re.DOTALL)

    selected_lines = lines[n_start:]
    for current_line, line in enumerate(selected_lines):
        splitted = line.split()
        if "KPOINTS| Special K-Point" in line:
            kpoint = tuple(float(p) for p in splitted[-3:])
            if " ".join(splitted[-5:-3]) != "not specified":
                label = splitted[-4]
                known_kpoints[kpoint] = label
        elif pattern.match(line):
            spin = int(splitted[3])
            kpoint = tuple(float(p) for p in splitted[-3:])
            kpoint_n_lines = int(math.ceil(int(selected_lines[current_line + 1]) / 4))
            band = [
                float(v)
                for v in " ".join(
                    selected_lines[current_line + 2 : current_line + 2 + kpoint_n_lines]
                ).split()
            ]

            if spin == 1:
                if kpoint in known_kpoints:
                    labels.append((len(kpoints), known_kpoints[kpoint]))
                kpoints.append(kpoint)
                bands_s1.append(band)
            elif spin == 2:
                bands_s2.append(band)

    if bands_s2:
        bands = [bands_s1, bands_s2]
    else:
        bands = bands_s1

    return np.array(kpoints), labels, np.array(bands)


def parse_cp2k_trajectory(fobj):
    """CP2K trajectory parser"""

    import numpy as np

    # pylint: disable=protected-access

    content = fobj.read()

    # parse coordinate section
    match = re.search(r"\n\s*&COORD\n(.*?)\n\s*&END COORD\n", content, re.DOTALL)
    coord_lines = [line.strip().split() for line in match.group(1).splitlines()]
    symbols = [line[0] for line in coord_lines]
    positions_str = [line[1:] for line in coord_lines]
    positions = np.array(positions_str, np.float64)

    # parse cell section
    match = re.search(r"\n\s*&CELL\n(.*?)\n\s*&END CELL\n", content, re.DOTALL)
    cell_lines = [line.strip().split() for line in match.group(1).splitlines()]
    cell_str = [line[1:] for line in cell_lines if line[0] in "ABC"]
    cell = np.array(cell_str, np.float64)

    return {"symbols": symbols, "positions": positions, "cell": cell}
